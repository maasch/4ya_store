{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea4533a",
   "metadata": {},
   "source": [
    "# SVD vs ALS (NMF) — Recommendation System Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275e595",
   "metadata": {},
   "source": [
    "This notebook:\n",
    "1. Loads and cleans the Amazon review dataset\n",
    "2. Prepares a shared train/test split\n",
    "3. Trains an **SVD** model (explicit rating prediction)\n",
    "4. Trains an **NMF** model (ALS-style matrix factorization)\n",
    "5. Compares both models on **RMSE, MAE, Precision@10, Recall@10**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7458719",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from surprise import SVD, NMF, Dataset, Reader, accuracy, Trainset\n",
    "from surprise.model_selection import train_test_split as surprise_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c59a7",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afcdcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_lines(filepath):\n",
    "    records = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                records.append(json.loads(line))\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "FILE_PATH = 'reco_dataset.json'\n",
    "\n",
    "df = load_json_lines(FILE_PATH)\n",
    "print(f\"Loaded {len(df):,} reviews\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a589d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba821d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6167f",
   "metadata": {},
   "source": [
    "### 3.1 Select Relevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = df[['reviewerID', 'asin', 'overall']].copy()\n",
    "\n",
    "print(f\"Users  : {df_cf['reviewerID'].nunique():,}\")\n",
    "print(f\"Items  : {df_cf['asin'].nunique():,}\")\n",
    "print(f\"Ratings: {len(df_cf):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f02e3a",
   "metadata": {},
   "source": [
    "### 3.2 Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84518283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values per column:\")\n",
    "print(df_cf.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad72106",
   "metadata": {},
   "source": [
    "### 3.3 Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before dedup: {len(df_cf):,} rows\")\n",
    "\n",
    "df_cf = df_cf.drop_duplicates(subset=['reviewerID', 'asin'], keep='last')\n",
    "\n",
    "print(f\"After dedup : {len(df_cf):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf7d10",
   "metadata": {},
   "source": [
    "### 3.4 Drop Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = df_cf.dropna(subset=['reviewerID', 'asin', 'overall'])\n",
    "\n",
    "print(f\"After dropping nulls: {len(df_cf):,} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf80d8",
   "metadata": {},
   "source": [
    "### 3.5 Validate Rating Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rating distribution before filter:\")\n",
    "print(df_cf['overall'].value_counts().sort_index())\n",
    "\n",
    "# Keep only valid ratings\n",
    "df_cf = df_cf[df_cf['overall'].between(1.0, 5.0)]\n",
    "\n",
    "print(f\"\\nAfter rating filter: {len(df_cf):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c1070",
   "metadata": {},
   "source": [
    "### 3.6 Filter Cold-Start Users & Items\n",
    "\n",
    "This is the most important cleaning step for matrix factorization. \n",
    "Users with only 1 or 2 ratings give the model nothing to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02921eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_USER_RATINGS = 5   # user must have rated at least 5 items\n",
    "MIN_ITEM_RATINGS = 5   # item must have been rated at least 5 times\n",
    "\n",
    "# Filter users\n",
    "user_counts = df_cf['reviewerID'].value_counts()\n",
    "valid_users = user_counts[user_counts >= MIN_USER_RATINGS].index\n",
    "df_cf = df_cf[df_cf['reviewerID'].isin(valid_users)]\n",
    "\n",
    "# Filter items\n",
    "item_counts = df_cf['asin'].value_counts()\n",
    "valid_items = item_counts[item_counts >= MIN_ITEM_RATINGS].index\n",
    "df_cf = df_cf[df_cf['asin'].isin(valid_items)]\n",
    "\n",
    "print(f\"After cold start filter:\")\n",
    "print(f\"  Users  : {df_cf['reviewerID'].nunique():,}\")\n",
    "print(f\"  Items  : {df_cf['asin'].nunique():,}\")\n",
    "print(f\"  Ratings: {len(df_cf):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce18e69",
   "metadata": {},
   "source": [
    "### 3.7 Final Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Final Clean Dataset ===\")\n",
    "print(f\"Shape       : {df_cf.shape}\")\n",
    "print(f\"Users       : {df_cf['reviewerID'].nunique():,}\")\n",
    "print(f\"Items       : {df_cf['asin'].nunique():,}\")\n",
    "print(f\"Ratings     : {len(df_cf):,}\")\n",
    "print(f\"Missing vals: {df_cf.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates  : {df_cf.duplicated().sum()}\")\n",
    "print(\"\\nRating distribution:\")\n",
    "print(df_cf['overall'].value_counts().sort_index())\n",
    "\n",
    "df_cf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45d518",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8423bff",
   "metadata": {},
   "source": [
    "### 4.1 Encode User & Item IDs to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "\n",
    "df_cf['user_id'] = user_enc.fit_transform(df_cf['reviewerID'])\n",
    "df_cf['item_id'] = item_enc.fit_transform(df_cf['asin'])\n",
    "\n",
    "n_users = df_cf['user_id'].nunique()\n",
    "n_items = df_cf['item_id'].nunique()\n",
    "\n",
    "print(f\"Number of users : {n_users:,}\")\n",
    "print(f\"Number of items : {n_items:,}\")\n",
    "print(f\"\\nSample encoding:\")\n",
    "df_cf[['reviewerID', 'user_id', 'asin', 'item_id', 'overall']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d77e33",
   "metadata": {},
   "source": [
    "### 4.2 Build the Sparse User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a242b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = csr_matrix(\n",
    "    (df_cf['overall'].astype(float),\n",
    "     (df_cf['user_id'], df_cf['item_id'])),\n",
    "    shape=(n_users, n_items)\n",
    ")\n",
    "\n",
    "# Check sparsity\n",
    "total_cells = n_users * n_items\n",
    "filled_cells = len(df_cf)\n",
    "sparsity = 1 - (filled_cells / total_cells)\n",
    "\n",
    "print(f\"Matrix shape : {sparse_matrix.shape}\")\n",
    "print(f\"Filled cells : {filled_cells:,}\")\n",
    "print(f\"Total cells  : {total_cells:,}\")\n",
    "print(f\"Sparsity     : {sparsity:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3381da6",
   "metadata": {},
   "source": [
    "### 4.3 Save Lookup Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map integer → original ID\n",
    "user_id_to_reviewer = {i: label for i, label in enumerate(user_enc.classes_)}\n",
    "item_id_to_asin     = {i: label for i, label in enumerate(item_enc.classes_)}\n",
    "\n",
    "# Map original ID → integer\n",
    "reviewer_to_user_id = {v: k for k, v in user_id_to_reviewer.items()}\n",
    "asin_to_item_id     = {v: k for k, v in item_id_to_asin.items()}\n",
    "\n",
    "print(f\"Sample user mapping: {list(user_id_to_reviewer.items())[:3]}\")\n",
    "print(f\"Sample item mapping: {list(item_id_to_asin.items())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbcfcc6",
   "metadata": {},
   "source": [
    "### 4.4 Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2514de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Feature Engineering Summary ===\")\n",
    "print(f\"df_cf columns     : {list(df_cf.columns)}\")\n",
    "print(f\"Sparse matrix type: {type(sparse_matrix)}\")\n",
    "print(f\"Matrix shape      : {sparse_matrix.shape}\")\n",
    "print(f\"Stored values     : {sparse_matrix.nnz:,}\")\n",
    "df_cf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea79d61",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Shared Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cc4c2",
   "metadata": {},
   "source": [
    "Both models (SVD and NMF) will be evaluated on the **exact same** \n",
    "train/test split for a fair comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb925c4",
   "metadata": {},
   "source": [
    "### 5.1 Sklearn Split (for sparse matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    df_cf,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_cf['user_id']\n",
    ")\n",
    "\n",
    "print(f\"Train size : {len(train_data):,} ratings\")\n",
    "print(f\"Test size  : {len(test_data):,} ratings\")\n",
    "print(f\"Train users: {train_data['user_id'].nunique():,}\")\n",
    "print(f\"Test users : {test_data['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492db44",
   "metadata": {},
   "source": [
    "### 5.2 Build Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f511930",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = csr_matrix(\n",
    "    (train_data['overall'].astype(float),\n",
    "     (train_data['user_id'], train_data['item_id'])),\n",
    "    shape=(n_users, n_items)\n",
    ")\n",
    "\n",
    "test_matrix = csr_matrix(\n",
    "    (test_data['overall'].astype(float),\n",
    "     (test_data['user_id'], test_data['item_id'])),\n",
    "    shape=(n_users, n_items)\n",
    ")\n",
    "\n",
    "print(f\"Train matrix shape : {train_matrix.shape}\")\n",
    "print(f\"Train matrix nnz   : {train_matrix.nnz:,}\")\n",
    "print(f\"Test matrix shape  : {test_matrix.shape}\")\n",
    "print(f\"Test matrix nnz    : {test_matrix.nnz:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac013a",
   "metadata": {},
   "source": [
    "### 5.3 Sanity Check — No Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23351fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = set(zip(train_data['user_id'], train_data['item_id']))\n",
    "test_pairs  = set(zip(test_data['user_id'],  test_data['item_id']))\n",
    "\n",
    "overlap = train_pairs & test_pairs\n",
    "print(f\"Overlapping user-item pairs: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a2652",
   "metadata": {},
   "source": [
    "### 5.4 Convert to Surprise Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad23ab7",
   "metadata": {},
   "source": [
    "Both SVD and NMF (from the Surprise library) need data in Surprise's internal format. \n",
    "We convert the **same** train/test split so both models see identical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Build Surprise trainset from our train_data\n",
    "surprise_full = Dataset.load_from_df(\n",
    "    df_cf[['reviewerID', 'asin', 'overall']], reader\n",
    ")\n",
    "\n",
    "# Build trainset using the same indices\n",
    "train_surprise = Dataset.load_from_df(\n",
    "    train_data[['reviewerID', 'asin', 'overall']], reader\n",
    ")\n",
    "trainset = train_surprise.build_full_trainset()\n",
    "\n",
    "# Build testset from test_data (list of tuples)\n",
    "testset = list(test_data[['reviewerID', 'asin', 'overall']].itertuples(index=False, name=None))\n",
    "\n",
    "print(f\"Surprise trainset: {trainset.n_ratings:,} ratings, {trainset.n_users:,} users, {trainset.n_items:,} items\")\n",
    "print(f\"Surprise testset : {len(testset):,} ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded8afd",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluation Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71564ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=4.0):\n",
    "    \"\"\"Compute Precision@K and Recall@K from Surprise predictions.\"\"\"\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions, recalls = {}, {}\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_relevant = sum(1 for (_, true_r) in user_ratings if true_r >= threshold)\n",
    "        n_hits     = sum(1 for (_, true_r) in user_ratings[:k] if true_r >= threshold)\n",
    "        precisions[uid] = n_hits / k\n",
    "        recalls[uid]    = n_hits / n_relevant if n_relevant > 0 else 0\n",
    "\n",
    "    avg_precision = sum(precisions.values()) / len(precisions)\n",
    "    avg_recall    = sum(recalls.values()) / len(recalls)\n",
    "    return avg_precision, avg_recall\n",
    "\n",
    "print(\"✅ Evaluation helper defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ece9d0",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Model 1 — SVD (Explicit Rating Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5fbe0",
   "metadata": {},
   "source": [
    "SVD (Singular Value Decomposition) from the Surprise library predicts explicit ratings.\n",
    "It learns user and item latent factor vectors directly from 1–5 star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e7941",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svd = SVD(\n",
    "    n_factors=50,\n",
    "    n_epochs=20,\n",
    "    lr_all=0.005,\n",
    "    reg_all=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training SVD model...\")\n",
    "model_svd.fit(trainset)\n",
    "print(\"✅ SVD model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00608cff",
   "metadata": {},
   "source": [
    "### 7.1 SVD Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f113d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "svd_predictions = model_svd.test(testset)\n",
    "\n",
    "# RMSE & MAE\n",
    "svd_rmse = accuracy.rmse(svd_predictions, verbose=True)\n",
    "svd_mae  = accuracy.mae(svd_predictions, verbose=True)\n",
    "\n",
    "# Precision@10 & Recall@10\n",
    "svd_precision, svd_recall = precision_recall_at_k(svd_predictions, k=10, threshold=4.0)\n",
    "\n",
    "print(f\"\\nSVD Precision@10 : {svd_precision:.4f} ({svd_precision*100:.2f}%)\")\n",
    "print(f\"SVD Recall@10    : {svd_recall:.4f} ({svd_recall*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12b48e",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Model 2 — NMF (ALS-Style Matrix Factorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c628367",
   "metadata": {},
   "source": [
    "NMF (Non-negative Matrix Factorization) from Surprise is an ALS-style algorithm.\n",
    "Like ALS, it decomposes the user-item matrix into non-negative latent factors.\n",
    "It uses the **same** train/test split as SVD for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89787a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nmf = NMF(\n",
    "    n_factors=50,\n",
    "    n_epochs=20,\n",
    "    reg_pu=0.1,       # user factor regularization\n",
    "    reg_qi=0.1,       # item factor regularization\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training NMF (ALS-style) model...\")\n",
    "model_nmf.fit(trainset)\n",
    "print(\"✅ NMF model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a03b29",
   "metadata": {},
   "source": [
    "### 8.1 NMF Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cde7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "nmf_predictions = model_nmf.test(testset)\n",
    "\n",
    "# RMSE & MAE\n",
    "nmf_rmse = accuracy.rmse(nmf_predictions, verbose=True)\n",
    "nmf_mae  = accuracy.mae(nmf_predictions, verbose=True)\n",
    "\n",
    "# Precision@10 & Recall@10\n",
    "nmf_precision, nmf_recall = precision_recall_at_k(nmf_predictions, k=10, threshold=4.0)\n",
    "\n",
    "print(f\"\\nNMF Precision@10 : {nmf_precision:.4f} ({nmf_precision*100:.2f}%)\")\n",
    "print(f\"NMF Recall@10    : {nmf_recall:.4f} ({nmf_recall*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4766c9",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Model Comparison — SVD vs NMF (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60280944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"   ALGORITHM COMPARISON ON SAME DATASET\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Metric':<20} {'SVD':>12} {'NMF (ALS)':>12}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'RMSE':<20} {svd_rmse:>12.4f} {nmf_rmse:>12.4f}\")\n",
    "print(f\"{'MAE':<20} {svd_mae:>12.4f} {nmf_mae:>12.4f}\")\n",
    "print(f\"{'Precision@10':<20} {svd_precision:>12.4f} {nmf_precision:>12.4f}\")\n",
    "print(f\"{'Recall@10':<20} {svd_recall:>12.4f} {nmf_recall:>12.4f}\")\n",
    "print(\"=\" * 55)\n",
    "print()\n",
    "print(\"NOTES:\")\n",
    "print(\"  Lower RMSE/MAE  = better rating prediction accuracy\")\n",
    "print(\"  Higher Prec/Rec = better at ranking relevant items\")\n",
    "print(\"  Both models trained on the SAME data split for fair comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfe1f1",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "| Model | Strengths | Best For |\n",
    "|-------|-----------|----------|\n",
    "| **SVD** | Learns biases, handles explicit ratings well | Rating prediction tasks |\n",
    "| **NMF (ALS)** | Non-negative factors, interpretable | Implicit feedback, when factors should be positive |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
